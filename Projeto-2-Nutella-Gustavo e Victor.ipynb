{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DUPLA: Gustavo Pierre e Victor Habib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEMA: Nutella"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 19/Set até às 23:59.<br />\n",
    "Grupo: 2 ou 3 pessoas - grupos com 3 pessoas terá uma rubrica diferenciada.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO gravar a key do professor no arquivo**\n",
    "\n",
    "\n",
    "### Entrega Intermediária: Check 1 - APS 2\n",
    "\n",
    "Até o dia 10/Set às 23:59, xlsx deve estar no Github com as seguintes evidências: \n",
    "\n",
    "  * Produto escolhido.\n",
    "  * Arquivo Excel contendo a base de treinamento e a base de testes já classificadas.\n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Parte I - Adquirindo a Base de Dados\n",
    "\n",
    "Acessar o notebook **Projeto-2-Planilha** para realizar a coleta dos dados. O grupo deve classificar os dados coletados manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Parte II - Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Não se esqueça de implementar o Laplace Smoothing (https://en.wikipedia.org/wiki/Laplace_smoothing).\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n",
    "Escreva o seu código abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1649,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as math\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from emoji import UNICODE_EMOJI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1650,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutella = pd.read_excel(\"tweets_nutella.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpar tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1651,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpo(tweet):\n",
    "    \n",
    "    tweets_limpos = []\n",
    "    \n",
    "    \n",
    "        \n",
    "    tweet=tweet.replace('@', '')\n",
    "\n",
    "    tweet=tweet.replace('.', '')\n",
    "\n",
    "    tweet=tweet.replace(',', '')\n",
    "\n",
    "    tweet=tweet.replace('rt ', '')\n",
    "\n",
    "    tweet=tweet.replace(':', '')\n",
    "\n",
    "    tweet=tweet.replace('_', '')\n",
    "\n",
    "    tweet=tweet.replace('+', '')\n",
    "\n",
    "    tweet=tweet.replace('-', '')\n",
    "\n",
    "    tweet=tweet.replace('(', '')\n",
    "\n",
    "    tweet=tweet.replace(')', '')\n",
    "\n",
    "    tweet=tweet.replace('/', '')\n",
    "\n",
    "    tweet=tweet.replace(';', '')\n",
    "\n",
    "    tweet=tweet.replace('>', '')\n",
    "\n",
    "    tweet=tweet.replace('<', '')\n",
    "\n",
    "    tweet=tweet.replace('=', '')\n",
    "\n",
    "    tweet=tweet.replace('#', '')\n",
    "\n",
    "    tweet=tweet.replace('!', '')\n",
    "\n",
    "    tweet=tweet.replace('*', '')\n",
    "\n",
    "    tweet=tweet.replace('&', '')\n",
    "\n",
    "    tweet=tweet.replace('$', '')\n",
    "\n",
    "    tweet=tweet.replace('}', '')\n",
    "\n",
    "    tweet=tweet.replace('{', '')\n",
    "\n",
    "    tweet=tweet.replace('£', '')\n",
    "\n",
    "    tweet=tweet.replace('[', '')\n",
    "\n",
    "    tweet=tweet.replace(']', '')\n",
    "\n",
    "    tweet=tweet.replace('?', '')\n",
    "\n",
    "    tweet=tweet.replace('\"', '')\n",
    "\n",
    "    tweets_limpos.append(tweet)\n",
    "\n",
    "    return tweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1652,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nutella[\"Treinamento\"] = nutella[\"Treinamento\"].apply(limpo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separação dos emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1653,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "emoji = []\n",
    "nutella\n",
    "for tweet in nutella[\"Treinamento\"]:\n",
    "    nada=''\n",
    "    for palavra in tweet:\n",
    "        if palavra in UNICODE_EMOJI:\n",
    "            nada=nada+' '+palavra+' '\n",
    "        else:\n",
    "            nada+=palavra\n",
    "    emoji.append(nada)\n",
    "    \n",
    "nutella[\"Treinamento\"]=emoji\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1654,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutella.Avaliação=nutella.Avaliação.astype(\"category\")\n",
    "nutella.Avaliação.cat.categories=(\"Relevante\", \"Irrelevante\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separar tweets em: relevante e irrelevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IRRELEVANTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1655,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 1655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irrelevantes_counts=nutella[\"Treinamento\"][nutella.Avaliação=='Irrelevante'].count()\n",
    "irrelevantes_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1656,
   "metadata": {},
   "outputs": [],
   "source": [
    "irrelevantes=nutella[\"Treinamento\"][nutella.Avaliação=='Irrelevante']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RELEVANTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1657,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 1657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevantes_counts=nutella[\"Treinamento\"][nutella.Avaliação=='Relevante'].count()\n",
    "relevantes_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1658,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevantes=nutella[\"Treinamento\"][nutella.Avaliação=='Relevante']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOTAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1659,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 1659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total=irrelevantes_counts+relevantes_counts\n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROBABILIDADE DOS TWEETS SEREM RELEVANTES OU IRRELEVANTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1660,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidade do tweet ser irrelevante: 43.00%\n",
      "Probabilidade do tweet ser relevante: 57.00%\n"
     ]
    }
   ],
   "source": [
    "p_tweet_irrelevante=irrelevantes_counts/total\n",
    "p_tweet_relevante=relevantes_counts/total\n",
    "\n",
    "print('Probabilidade do tweet ser irrelevante: {0:.2f}%'.format(p_tweet_irrelevante*100))\n",
    "print('Probabilidade do tweet ser relevante: {0:.2f}%'.format(p_tweet_relevante*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contar palavras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IRRELEVANTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1680,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de palavras que aparecem nos tweets classificados como irrelevantes COM repetiçaõ: 2199\n",
      "\n",
      "\n",
      "len de irrelevantes: 2199\n"
     ]
    }
   ],
   "source": [
    "palavras_irrelevantes=[]\n",
    "\n",
    "for linha in irrelevantes:\n",
    "    separacao=linha.split()\n",
    "    for palavra in separacao:\n",
    "        palavras_irrelevantes.append(palavra)\n",
    "\n",
    "\n",
    "print('Quantidade de palavras que aparecem nos tweets classificados como irrelevantes COM repetiçaõ: {0}'.format(len(palavras_irrelevantes)))\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('')\n",
    "print('len de irrelevantes: {0}'.format(len(palavras_irrelevantes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1682,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " possibilidade de irrelevantes: 938\n"
     ]
    }
   ],
   "source": [
    "conta_palavras_irrelevantes=pd.Series(palavras_irrelevantes).value_counts()\n",
    "\n",
    "#print('\\nContagem de palavras que aparecem nos tweets classificados como irrelevantes')\n",
    "print('\\n possibilidade de irrelevantes: {0}'.format(len(conta_palavras_irrelevantes)))\n",
    "\n",
    "#conta_palavras_irrelevantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RELEVANTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1683,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de palavras que aparecem nos tweets classificados como relevantes COM repetiçaõ: 2544\n",
      "\n",
      "\n",
      "len de relevantes: 2544\n"
     ]
    }
   ],
   "source": [
    "palavras_relevantes=[]\n",
    "for linha in relevantes:\n",
    "    separacao=linha.split()\n",
    "    for palavra in separacao:\n",
    "        palavras_relevantes.append(palavra)\n",
    "        \n",
    "print('Quantidade de palavras que aparecem nos tweets classificados como relevantes COM repetiçaõ: {0}'.format(len(palavras_relevantes)))\n",
    "print('')\n",
    "        \n",
    "\n",
    "print('')\n",
    "print('len de relevantes: {0}'.format(len(palavras_relevantes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1684,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "possibilidade de relevantes: 775\n"
     ]
    }
   ],
   "source": [
    "conta_palavras_relevantes=pd.Series(palavras_relevantes).value_counts()\n",
    "\n",
    "#print('\\nContagem de palavras que aparecem nos tweets classificados como relevantes')\n",
    "print('\\npossibilidade de relevantes: {0}'.format(len(conta_palavras_relevantes)))\n",
    "#conta_palavras_relevantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOTAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1686,
   "metadata": {},
   "outputs": [],
   "source": [
    "contagem_palavras_total=pd.Series(palavra_total).value_counts()\n",
    "#print(\"\\nContagem de palavras que aparecem em ambos os tweets\")\n",
    "#contagem_palavras_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1687,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4743"
      ]
     },
     "execution_count": 1687,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavra_total = []\n",
    "\n",
    "for e in palavras_irrelevantes:\n",
    "        palavra_total.append(e)\n",
    "for y in palavras_relevantes:\n",
    "        palavra_total.append(y)\n",
    "\n",
    "\n",
    "conta_palavras_total\n",
    "len(palavra_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilidades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- P(Palavra|Relevante) = (ocorrencia da palavra + 1) / (len(relevante) + possibilidade de palavras)\n",
    "- P(Palavra|Irreelevante) = (ocorrencia da palavra + 1) / (len(irrelevante) + possibilidade de palavras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- P(Palavra|Relevante) = (conta_palavras_relevantes[palavra] + 1) / (len(palavras_relevantes) + len(contagem_palavras_total))\n",
    "- P(Palavra|Irrelevante) = (conta_palavras_irrelevantes[palavra] + 1) / (len(palavras_irrelevantes) + len(contagem_palavras_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1667,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificador_palavras(palavra):\n",
    "    \n",
    "\n",
    "    if palavra in palavra_total:\n",
    "        \n",
    "        if palavra in palavras_relevantes and palavra in palavras_irrelevantes:\n",
    "            prob_relevante= (conta_palavras_relevantes[palavra] + 1) / (len(palavras_relevantes) + len(contagem_palavras_total))\n",
    "            prob_irrelevante = (conta_palavras_irrelevantes[palavra] + 1) / (len(palavras_irrelevantes) + len(contagem_palavras_total))\n",
    "           \n",
    "        \n",
    "        elif palavra in palavras_irrelevantes:\n",
    "            prob_irrelevante=(conta_palavras_irrelevantes[palavra] + 1) / (len(palavras_irrelevantes) + len(contagem_palavras_total))\n",
    "            prob_relevante = (0 + 1) / (len(palavras_relevantes) + len(contagem_palavras_total))\n",
    "        \n",
    "        elif palavra in palavras_relevantes:\n",
    "            prob_relevante=(conta_palavras_relevantes[palavra] + 1) / (len(palavras_relevantes) + len(contagem_palavras_total))\n",
    "            prob_irrelevante =  (0 + 1) / (len(palavras_irrelevantes) + len(contagem_palavras_total))\n",
    "    \n",
    "    else:\n",
    "        prob_relevante = (0 + 1) / (len(palavras_relevantes) + len(contagem_palavras_total))\n",
    "        prob_irrelevante =  (0 + 1) / (len(palavras_irrelevantes) + len(contagem_palavras_total))\n",
    "        \n",
    "    return[prob_relevante, prob_irrelevante]\n",
    "\n",
    "\n",
    "#print(classificador_palavras('nutella'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- P(Tweet|Relevante) = P(Palavra_1|Relevante) * P(Palavra_2|Relevante) * P(Palavra_3|Relevante) * ... * P(Palavra_n|Relevante)\n",
    "- P(Tweet|Irrelevante) = P(Palavra_1|Irrelevante) * P(Palavra_2|Irrelevante) * P(Palavra_3|Irrelevante) * ... * P(Palavra_n|Irrelevante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1691,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificador_tweet(tweet):\n",
    "    probabilidade_tweet_relevante=1\n",
    "    probabilidade_tweet_irrelevante=1\n",
    "    limpa=limpo(tweet)\n",
    "    separa_palavra=limpa.split()\n",
    "    for palavra in separa_palavra: \n",
    "        probabilidades=classificador_palavras(palavra)\n",
    "        \n",
    "        probabilidade_tweet_relevante=probabilidades[0]*probabilidade_tweet_relevante\n",
    "        probabilidade_tweet_irrelevante=probabilidades[1]*probabilidade_tweet_irrelevante\n",
    "        \n",
    "    if probabilidade_tweet_relevante > probabilidade_tweet_irrelevante:\n",
    "        return 'Relevante'\n",
    "    \n",
    "    elif probabilidade_tweet_relevante < probabilidade_tweet_irrelevante:\n",
    "        return 'Irrelevante'\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1692,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutella_teste=pd.read_excel(\"tweets_nutella.xlsx\", \"Teste\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1693,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutella_teste.Avaliação=nutella_teste.Avaliação.astype(\"category\")\n",
    "nutella_teste.Avaliação.cat.categories=(\"Relevante\", \"Irrelevante\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1695,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "probs_teste=[]\n",
    "for tweet in nutella_teste[\"Teste\"]:\n",
    "    probs=classificador_tweet(tweet)\n",
    "    probs_teste.append(probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1696,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Avaliação</th>\n",
       "      <th>Classificados testes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt @arttyoongi: só fui eu que vi ou vocês tamb...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@quefilhodaputa nutella é ruim</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@spunk182 @esp_interativo esse termo é usado d...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@arqtricolor isso aí! nada de arena nutella 😎!...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt @clubefollowback: já temos até bolsonarista...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste    Avaliação  \\\n",
       "0  rt @arttyoongi: só fui eu que vi ou vocês tamb...  Irrelevante   \n",
       "1                     @quefilhodaputa nutella é ruim    Relevante   \n",
       "2  @spunk182 @esp_interativo esse termo é usado d...  Irrelevante   \n",
       "3  @arqtricolor isso aí! nada de arena nutella 😎!...  Irrelevante   \n",
       "4  rt @clubefollowback: já temos até bolsonarista...  Irrelevante   \n",
       "\n",
       "  Classificados testes  \n",
       "0          Irrelevante  \n",
       "1            Relevante  \n",
       "2          Irrelevante  \n",
       "3          Irrelevante  \n",
       "4          Irrelevante  "
      ]
     },
     "execution_count": 1696,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nutella_teste[\"Classificados testes\"]=pd.Series(probs_teste)\n",
    "nutella_teste.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Obrigatório para grupos de 3 alunos:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1697,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acertos: 179. Probabilidade de acerto: 89.5%\n",
      "Erros: 21. Probabilidade de erro: 10.5%\n"
     ]
    }
   ],
   "source": [
    "acertos=0\n",
    "erros=0\n",
    "lista = []\n",
    "i=0\n",
    "    \n",
    "for x in nutella_teste.Avaliação:\n",
    "    lista.append(x)\n",
    "    \n",
    "while i < len(probs_teste):\n",
    "    if probs_teste[i]==lista[i]:\n",
    "        acertos+=1\n",
    "        i+=1\n",
    "    else:\n",
    "        erros+=1\n",
    "        i+=1\n",
    "        \n",
    "\n",
    "print('Acertos: {0}. Probabilidade de acerto: {1}%'.format(acertos, acertos/200*100))\n",
    "print('Erros: {0}. Probabilidade de erro: {1}%'.format(erros, erros/200*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1698,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv = nutella_teste[(nutella_teste[\"Avaliação\"]==\"Relevante\")&(nutella_teste[\"Classificados testes\"]==\"Relevante\")]\n",
    "\n",
    "nv = nutella_teste[(nutella_teste[\"Avaliação\"]==\"Irrelevante\")&(nutella_teste[\"Classificados testes\"]==\"Irrelevante\")]\n",
    "\n",
    "nf = nutella_teste[(nutella_teste[\"Avaliação\"]==\"Relevante\")&(nutella_teste[\"Classificados testes\"]==\"Irrelevante\")]\n",
    "\n",
    "pf = nutella_teste[(nutella_teste[\"Avaliação\"]==\"Irrelevante\")&(nutella_teste[\"Classificados testes\"]==\"Relevante\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1699,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem de positivo verdadeiro: 59.00%\n"
     ]
    }
   ],
   "source": [
    "prob_positivo_verdadeiro = len(pv[\"Avaliação\"])/len(nutella_teste[\"Avaliação\"])\n",
    "print(\"Porcentagem de positivo verdadeiro: {0:.2f}%\".format(prob_positivo_verdadeiro*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1700,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem de negativo verdadeiro: 30.50%\n"
     ]
    }
   ],
   "source": [
    "prob_negativos_verdadeiros = len(fv[\"Avaliação\"])/len(nutella_teste[\"Avaliação\"])\n",
    "print(\"Porcentagem de negativo verdadeiro: {0:.2f}%\".format(prob_negativos_verdadeiros*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1701,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem de negativo falso: 2.00%\n"
     ]
    }
   ],
   "source": [
    "prob_negativos_falsos = len(nf[\"Avaliação\"])/len(nutella_teste[\"Avaliação\"])\n",
    "print(\"Porcentagem de negativo falso: {0:.2f}%\".format(prob_negativos_falsos*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1702,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem de positivo falso: 8.50%\n"
     ]
    }
   ],
   "source": [
    "prob_positivo_falso = len(pf[\"Avaliação\"])/len(nutella_teste[\"Avaliação\"])\n",
    "print(\"Porcentagem de positivo falso: {0:.2f}%\".format(prob_positivo_falso*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseando-se na análise qualitativa das medidas obtidas, o classificador implementado pode ser considerado confiável. Os tweets referentes a nutella, em geral, apresentam duas contextualizações. Uma delas faz referência ao produto, e a outra é utilizada na forma de adjetivo. Isso ocorre, pois o termo nutella foi adotado pela sociedade associado a algo que remete a modernidade, e no termo mais popular, \"frescura\". Nesse sentido, a palavra nutella é acompanhada implicita ou explicitamente da palavra \"raiz\", definida como o oposto: antiguidade e jeito bruto de ser ou agir. Em suma, como essas contextualizações são completamente independendes e irrelacionáveis, algumas palavras-chave que estão presentes nos tweets classificados como irrelevantes, não se encontram nos tweets classificados como relevantes, o que aumenta as chances de sucesso do classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com relação ao tratamento de mensagens com dupla negação e sarcasmo pode-se dizer que não houve muitas ocorrências desse tipo de tweet, tanto na planilha de treinamento, quanto na de teste. Entretanto, das poucas vezes que apareceu, consideramos todas as frases no sentido literal, desconsiderando qualquer forma de ironia. É inegável que isso prejudica a leitura e classificação dos tweets, mas diferente dos seres humanos, a máquina ainda não é 100% eficaz quando frases conotativas ou que apresentem sentidos inversos são dadas a elas para interpretarem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pensando em um plano de expansão, é valido dizer que a base está praticamente concluída. O classificador se encontra com uma probabilidade de acerto de 89,5%, apresentando um grande potencial de melhora. Dessa forma, acreditamos que manter o financimento do projeto pode trazer benefícios tanto aos criadores financiados quanto aos financiadores. Para maximizar o sucesso do classificador, algumas breves implementações podem ser introduzidas, como: maior filtragem dos tweets (limpar mais caracteres indesejados) e mais quantidades de tweets. Assim, a manutenção do financiamento permitiria que avançássemos no projeto."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
