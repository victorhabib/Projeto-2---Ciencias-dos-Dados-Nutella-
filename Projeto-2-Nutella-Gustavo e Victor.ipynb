{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DUPLA: Gustavo Pierre e Victor Habib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEMA: Nutella"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Autom√°tico de Sentimento\n",
    "\n",
    "Voc√™ foi contratado por uma empresa parar analisar como os clientes est√£o reagindo a um determinado produto no Twitter. A empresa deseja que voc√™ crie um programa que ir√° analisar as mensagens dispon√≠veis e classificar√° como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mere√ßam destaque, disparem um foco de aten√ß√£o da √°rea de marketing.<br /><br />\n",
    "Como aluno de Ci√™ncia dos Dados, voc√™ lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que √© largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conte√∫do.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, voc√™ precisa implementar uma vers√£o do classificador que \"aprende\" o que √© relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Ap√≥s validado, o seu prot√≥tipo poder√° tamb√©m capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informa√ß√µes do Projeto\n",
    "\n",
    "Prazo: 19/Set at√© √†s 23:59.<br />\n",
    "Grupo: 2 ou 3 pessoas - grupos com 3 pessoas ter√° uma rubrica diferenciada.<br /><br />\n",
    "Entreg√°veis via GitHub: \n",
    "* Arquivo notebook com o c√≥digo do classificador, seguindo as orienta√ß√µes abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**N√ÉO gravar a key do professor no arquivo**\n",
    "\n",
    "\n",
    "### Entrega Intermedi√°ria: Check 1 - APS 2\n",
    "\n",
    "At√© o dia 10/Set √†s 23:59, xlsx deve estar no Github com as seguintes evid√™ncias: \n",
    "\n",
    "  * Produto escolhido.\n",
    "  * Arquivo Excel contendo a base de treinamento e a base de testes j√° classificadas.\n",
    "\n",
    "Sugest√£o de leitura:<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Parte I - Adquirindo a Base de Dados\n",
    "\n",
    "Acessar o notebook **Projeto-2-Planilha** para realizar a coleta dos dados. O grupo deve classificar os dados coletados manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Parte II - Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. N√£o se esque√ßa de implementar o Laplace Smoothing (https://en.wikipedia.org/wiki/Laplace_smoothing).\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. N√£o remover emojis.<br />\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o.\n",
    "\n",
    "Escreva o seu c√≥digo abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1649,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as math\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from emoji import UNICODE_EMOJI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1650,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutella = pd.read_excel(\"tweets_nutella.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpar tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1651,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpo(tweet):\n",
    "    \n",
    "    tweets_limpos = []\n",
    "    \n",
    "    \n",
    "        \n",
    "    tweet=tweet.replace('@', '')\n",
    "\n",
    "    tweet=tweet.replace('.', '')\n",
    "\n",
    "    tweet=tweet.replace(',', '')\n",
    "\n",
    "    tweet=tweet.replace('rt ', '')\n",
    "\n",
    "    tweet=tweet.replace(':', '')\n",
    "\n",
    "    tweet=tweet.replace('_', '')\n",
    "\n",
    "    tweet=tweet.replace('+', '')\n",
    "\n",
    "    tweet=tweet.replace('-', '')\n",
    "\n",
    "    tweet=tweet.replace('(', '')\n",
    "\n",
    "    tweet=tweet.replace(')', '')\n",
    "\n",
    "    tweet=tweet.replace('/', '')\n",
    "\n",
    "    tweet=tweet.replace(';', '')\n",
    "\n",
    "    tweet=tweet.replace('>', '')\n",
    "\n",
    "    tweet=tweet.replace('<', '')\n",
    "\n",
    "    tweet=tweet.replace('=', '')\n",
    "\n",
    "    tweet=tweet.replace('#', '')\n",
    "\n",
    "    tweet=tweet.replace('!', '')\n",
    "\n",
    "    tweet=tweet.replace('*', '')\n",
    "\n",
    "    tweet=tweet.replace('&', '')\n",
    "\n",
    "    tweet=tweet.replace('$', '')\n",
    "\n",
    "    tweet=tweet.replace('}', '')\n",
    "\n",
    "    tweet=tweet.replace('{', '')\n",
    "\n",
    "    tweet=tweet.replace('¬£', '')\n",
    "\n",
    "    tweet=tweet.replace('[', '')\n",
    "\n",
    "    tweet=tweet.replace(']', '')\n",
    "\n",
    "    tweet=tweet.replace('?', '')\n",
    "\n",
    "    tweet=tweet.replace('\"', '')\n",
    "\n",
    "    tweets_limpos.append(tweet)\n",
    "\n",
    "    return tweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1652,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nutella[\"Treinamento\"] = nutella[\"Treinamento\"].apply(limpo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separa√ß√£o dos emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1653,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "emoji = []\n",
    "nutella\n",
    "for tweet in nutella[\"Treinamento\"]:\n",
    "    nada=''\n",
    "    for palavra in tweet:\n",
    "        if palavra in UNICODE_EMOJI:\n",
    "            nada=nada+' '+palavra+' '\n",
    "        else:\n",
    "            nada+=palavra\n",
    "    emoji.append(nada)\n",
    "    \n",
    "nutella[\"Treinamento\"]=emoji\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1654,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutella.Avalia√ß√£o=nutella.Avalia√ß√£o.astype(\"category\")\n",
    "nutella.Avalia√ß√£o.cat.categories=(\"Relevante\", \"Irrelevante\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separar tweets em: relevante e irrelevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IRRELEVANTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1655,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 1655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irrelevantes_counts=nutella[\"Treinamento\"][nutella.Avalia√ß√£o=='Irrelevante'].count()\n",
    "irrelevantes_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1656,
   "metadata": {},
   "outputs": [],
   "source": [
    "irrelevantes=nutella[\"Treinamento\"][nutella.Avalia√ß√£o=='Irrelevante']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RELEVANTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1657,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 1657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevantes_counts=nutella[\"Treinamento\"][nutella.Avalia√ß√£o=='Relevante'].count()\n",
    "relevantes_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1658,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevantes=nutella[\"Treinamento\"][nutella.Avalia√ß√£o=='Relevante']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOTAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1659,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 1659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total=irrelevantes_counts+relevantes_counts\n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROBABILIDADE DOS TWEETS SEREM RELEVANTES OU IRRELEVANTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1660,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidade do tweet ser irrelevante: 43.00%\n",
      "Probabilidade do tweet ser relevante: 57.00%\n"
     ]
    }
   ],
   "source": [
    "p_tweet_irrelevante=irrelevantes_counts/total\n",
    "p_tweet_relevante=relevantes_counts/total\n",
    "\n",
    "print('Probabilidade do tweet ser irrelevante: {0:.2f}%'.format(p_tweet_irrelevante*100))\n",
    "print('Probabilidade do tweet ser relevante: {0:.2f}%'.format(p_tweet_relevante*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contar palavras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IRRELEVANTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1680,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de palavras que aparecem nos tweets classificados como irrelevantes COM repeti√ßa√µ: 2199\n",
      "\n",
      "\n",
      "len de irrelevantes: 2199\n"
     ]
    }
   ],
   "source": [
    "palavras_irrelevantes=[]\n",
    "\n",
    "for linha in irrelevantes:\n",
    "    separacao=linha.split()\n",
    "    for palavra in separacao:\n",
    "        palavras_irrelevantes.append(palavra)\n",
    "\n",
    "\n",
    "print('Quantidade de palavras que aparecem nos tweets classificados como irrelevantes COM repeti√ßa√µ: {0}'.format(len(palavras_irrelevantes)))\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('')\n",
    "print('len de irrelevantes: {0}'.format(len(palavras_irrelevantes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1682,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " possibilidade de irrelevantes: 938\n"
     ]
    }
   ],
   "source": [
    "conta_palavras_irrelevantes=pd.Series(palavras_irrelevantes).value_counts()\n",
    "\n",
    "#print('\\nContagem de palavras que aparecem nos tweets classificados como irrelevantes')\n",
    "print('\\n possibilidade de irrelevantes: {0}'.format(len(conta_palavras_irrelevantes)))\n",
    "\n",
    "#conta_palavras_irrelevantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RELEVANTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1683,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de palavras que aparecem nos tweets classificados como relevantes COM repeti√ßa√µ: 2544\n",
      "\n",
      "\n",
      "len de relevantes: 2544\n"
     ]
    }
   ],
   "source": [
    "palavras_relevantes=[]\n",
    "for linha in relevantes:\n",
    "    separacao=linha.split()\n",
    "    for palavra in separacao:\n",
    "        palavras_relevantes.append(palavra)\n",
    "        \n",
    "print('Quantidade de palavras que aparecem nos tweets classificados como relevantes COM repeti√ßa√µ: {0}'.format(len(palavras_relevantes)))\n",
    "print('')\n",
    "        \n",
    "\n",
    "print('')\n",
    "print('len de relevantes: {0}'.format(len(palavras_relevantes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1684,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "possibilidade de relevantes: 775\n"
     ]
    }
   ],
   "source": [
    "conta_palavras_relevantes=pd.Series(palavras_relevantes).value_counts()\n",
    "\n",
    "#print('\\nContagem de palavras que aparecem nos tweets classificados como relevantes')\n",
    "print('\\npossibilidade de relevantes: {0}'.format(len(conta_palavras_relevantes)))\n",
    "#conta_palavras_relevantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOTAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1686,
   "metadata": {},
   "outputs": [],
   "source": [
    "contagem_palavras_total=pd.Series(palavra_total).value_counts()\n",
    "#print(\"\\nContagem de palavras que aparecem em ambos os tweets\")\n",
    "#contagem_palavras_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1687,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4743"
      ]
     },
     "execution_count": 1687,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavra_total = []\n",
    "\n",
    "for e in palavras_irrelevantes:\n",
    "        palavra_total.append(e)\n",
    "for y in palavras_relevantes:\n",
    "        palavra_total.append(y)\n",
    "\n",
    "\n",
    "conta_palavras_total\n",
    "len(palavra_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilidades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- P(Palavra|Relevante) = (ocorrencia da palavra + 1) / (len(relevante) + possibilidade de palavras)\n",
    "- P(Palavra|Irreelevante) = (ocorrencia da palavra + 1) / (len(irrelevante) + possibilidade de palavras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- P(Palavra|Relevante) = (conta_palavras_relevantes[palavra] + 1) / (len(palavras_relevantes) + len(contagem_palavras_total))\n",
    "- P(Palavra|Irrelevante) = (conta_palavras_irrelevantes[palavra] + 1) / (len(palavras_irrelevantes) + len(contagem_palavras_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1667,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificador_palavras(palavra):\n",
    "    \n",
    "\n",
    "    if palavra in palavra_total:\n",
    "        \n",
    "        if palavra in palavras_relevantes and palavra in palavras_irrelevantes:\n",
    "            prob_relevante= (conta_palavras_relevantes[palavra] + 1) / (len(palavras_relevantes) + len(contagem_palavras_total))\n",
    "            prob_irrelevante = (conta_palavras_irrelevantes[palavra] + 1) / (len(palavras_irrelevantes) + len(contagem_palavras_total))\n",
    "           \n",
    "        \n",
    "        elif palavra in palavras_irrelevantes:\n",
    "            prob_irrelevante=(conta_palavras_irrelevantes[palavra] + 1) / (len(palavras_irrelevantes) + len(contagem_palavras_total))\n",
    "            prob_relevante = (0 + 1) / (len(palavras_relevantes) + len(contagem_palavras_total))\n",
    "        \n",
    "        elif palavra in palavras_relevantes:\n",
    "            prob_relevante=(conta_palavras_relevantes[palavra] + 1) / (len(palavras_relevantes) + len(contagem_palavras_total))\n",
    "            prob_irrelevante =  (0 + 1) / (len(palavras_irrelevantes) + len(contagem_palavras_total))\n",
    "    \n",
    "    else:\n",
    "        prob_relevante = (0 + 1) / (len(palavras_relevantes) + len(contagem_palavras_total))\n",
    "        prob_irrelevante =  (0 + 1) / (len(palavras_irrelevantes) + len(contagem_palavras_total))\n",
    "        \n",
    "    return[prob_relevante, prob_irrelevante]\n",
    "\n",
    "\n",
    "#print(classificador_palavras('nutella'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- P(Tweet|Relevante) = P(Palavra_1|Relevante) * P(Palavra_2|Relevante) * P(Palavra_3|Relevante) * ... * P(Palavra_n|Relevante)\n",
    "- P(Tweet|Irrelevante) = P(Palavra_1|Irrelevante) * P(Palavra_2|Irrelevante) * P(Palavra_3|Irrelevante) * ... * P(Palavra_n|Irrelevante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1691,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificador_tweet(tweet):\n",
    "    probabilidade_tweet_relevante=1\n",
    "    probabilidade_tweet_irrelevante=1\n",
    "    limpa=limpo(tweet)\n",
    "    separa_palavra=limpa.split()\n",
    "    for palavra in separa_palavra: \n",
    "        probabilidades=classificador_palavras(palavra)\n",
    "        \n",
    "        probabilidade_tweet_relevante=probabilidades[0]*probabilidade_tweet_relevante\n",
    "        probabilidade_tweet_irrelevante=probabilidades[1]*probabilidade_tweet_irrelevante\n",
    "        \n",
    "    if probabilidade_tweet_relevante > probabilidade_tweet_irrelevante:\n",
    "        return 'Relevante'\n",
    "    \n",
    "    elif probabilidade_tweet_relevante < probabilidade_tweet_irrelevante:\n",
    "        return 'Irrelevante'\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1692,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutella_teste=pd.read_excel(\"tweets_nutella.xlsx\", \"Teste\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1693,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutella_teste.Avalia√ß√£o=nutella_teste.Avalia√ß√£o.astype(\"category\")\n",
    "nutella_teste.Avalia√ß√£o.cat.categories=(\"Relevante\", \"Irrelevante\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1695,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "probs_teste=[]\n",
    "for tweet in nutella_teste[\"Teste\"]:\n",
    "    probs=classificador_tweet(tweet)\n",
    "    probs_teste.append(probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1696,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Avalia√ß√£o</th>\n",
       "      <th>Classificados testes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt @arttyoongi: s√≥ fui eu que vi ou voc√™s tamb...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@quefilhodaputa nutella √© ruim</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@spunk182 @esp_interativo esse termo √© usado d...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@arqtricolor isso a√≠! nada de arena nutella üòé!...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt @clubefollowback: j√° temos at√© bolsonarista...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste    Avalia√ß√£o  \\\n",
       "0  rt @arttyoongi: s√≥ fui eu que vi ou voc√™s tamb...  Irrelevante   \n",
       "1                     @quefilhodaputa nutella √© ruim    Relevante   \n",
       "2  @spunk182 @esp_interativo esse termo √© usado d...  Irrelevante   \n",
       "3  @arqtricolor isso a√≠! nada de arena nutella üòé!...  Irrelevante   \n",
       "4  rt @clubefollowback: j√° temos at√© bolsonarista...  Irrelevante   \n",
       "\n",
       "  Classificados testes  \n",
       "0          Irrelevante  \n",
       "1            Relevante  \n",
       "2          Irrelevante  \n",
       "3          Irrelevante  \n",
       "4          Irrelevante  "
      ]
     },
     "execution_count": 1696,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nutella_teste[\"Classificados testes\"]=pd.Series(probs_teste)\n",
    "nutella_teste.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora voc√™ deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Voc√™ deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas n√£o s√£o relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e s√£o relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como n√£o relevante e n√£o s√£o relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como n√£o relevante e s√£o relevantes)\n",
    "\n",
    "Obrigat√≥rio para grupos de 3 alunos:\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseado na diferen√ßa de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1697,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acertos: 179. Probabilidade de acerto: 89.5%\n",
      "Erros: 21. Probabilidade de erro: 10.5%\n"
     ]
    }
   ],
   "source": [
    "acertos=0\n",
    "erros=0\n",
    "lista = []\n",
    "i=0\n",
    "    \n",
    "for x in nutella_teste.Avalia√ß√£o:\n",
    "    lista.append(x)\n",
    "    \n",
    "while i < len(probs_teste):\n",
    "    if probs_teste[i]==lista[i]:\n",
    "        acertos+=1\n",
    "        i+=1\n",
    "    else:\n",
    "        erros+=1\n",
    "        i+=1\n",
    "        \n",
    "\n",
    "print('Acertos: {0}. Probabilidade de acerto: {1}%'.format(acertos, acertos/200*100))\n",
    "print('Erros: {0}. Probabilidade de erro: {1}%'.format(erros, erros/200*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1698,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv = nutella_teste[(nutella_teste[\"Avalia√ß√£o\"]==\"Relevante\")&(nutella_teste[\"Classificados testes\"]==\"Relevante\")]\n",
    "\n",
    "nv = nutella_teste[(nutella_teste[\"Avalia√ß√£o\"]==\"Irrelevante\")&(nutella_teste[\"Classificados testes\"]==\"Irrelevante\")]\n",
    "\n",
    "nf = nutella_teste[(nutella_teste[\"Avalia√ß√£o\"]==\"Relevante\")&(nutella_teste[\"Classificados testes\"]==\"Irrelevante\")]\n",
    "\n",
    "pf = nutella_teste[(nutella_teste[\"Avalia√ß√£o\"]==\"Irrelevante\")&(nutella_teste[\"Classificados testes\"]==\"Relevante\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1699,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem de positivo verdadeiro: 59.00%\n"
     ]
    }
   ],
   "source": [
    "prob_positivo_verdadeiro = len(pv[\"Avalia√ß√£o\"])/len(nutella_teste[\"Avalia√ß√£o\"])\n",
    "print(\"Porcentagem de positivo verdadeiro: {0:.2f}%\".format(prob_positivo_verdadeiro*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1700,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem de negativo verdadeiro: 30.50%\n"
     ]
    }
   ],
   "source": [
    "prob_negativos_verdadeiros = len(fv[\"Avalia√ß√£o\"])/len(nutella_teste[\"Avalia√ß√£o\"])\n",
    "print(\"Porcentagem de negativo verdadeiro: {0:.2f}%\".format(prob_negativos_verdadeiros*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1701,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem de negativo falso: 2.00%\n"
     ]
    }
   ],
   "source": [
    "prob_negativos_falsos = len(nf[\"Avalia√ß√£o\"])/len(nutella_teste[\"Avalia√ß√£o\"])\n",
    "print(\"Porcentagem de negativo falso: {0:.2f}%\".format(prob_negativos_falsos*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1702,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem de positivo falso: 8.50%\n"
     ]
    }
   ],
   "source": [
    "prob_positivo_falso = len(pf[\"Avalia√ß√£o\"])/len(nutella_teste[\"Avalia√ß√£o\"])\n",
    "print(\"Porcentagem de positivo falso: {0:.2f}%\".format(prob_positivo_falso*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclus√£o.<br /> \n",
    "Fa√ßa um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como s√£o tratadas as mensagens com dupla nega√ß√£o e sarcasmo.<br />\n",
    "Proponha um plano de expans√£o. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que n√£o posso alimentar minha base de Treinamento automaticamente usando o pr√≥prio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cen√°rios de uso para o classificador Naive-Bayes. Cen√°rios sem intersec√ß√£o com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indica√ß√µes concretas de como implementar (n√£o √© preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseando-se na an√°lise qualitativa das medidas obtidas, o classificador implementado pode ser considerado confi√°vel. Os tweets referentes a nutella, em geral, apresentam duas contextualiza√ß√µes. Uma delas faz refer√™ncia ao produto, e a outra √© utilizada na forma de adjetivo. Isso ocorre, pois o termo nutella foi adotado pela sociedade associado a algo que remete a modernidade, e no termo mais popular, \"frescura\". Nesse sentido, a palavra nutella √© acompanhada implicita ou explicitamente da palavra \"raiz\", definida como o oposto: antiguidade e jeito bruto de ser ou agir. Em suma, como essas contextualiza√ß√µes s√£o completamente independendes e irrelacion√°veis, algumas palavras-chave que est√£o presentes nos tweets classificados como irrelevantes, n√£o se encontram nos tweets classificados como relevantes, o que aumenta as chances de sucesso do classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com rela√ß√£o ao tratamento de mensagens com dupla nega√ß√£o e sarcasmo pode-se dizer que n√£o houve muitas ocorr√™ncias desse tipo de tweet, tanto na planilha de treinamento, quanto na de teste. Entretanto, das poucas vezes que apareceu, consideramos todas as frases no sentido literal, desconsiderando qualquer forma de ironia. √â ineg√°vel que isso prejudica a leitura e classifica√ß√£o dos tweets, mas diferente dos seres humanos, a m√°quina ainda n√£o √© 100% eficaz quando frases conotativas ou que apresentem sentidos inversos s√£o dadas a elas para interpretarem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pensando em um plano de expans√£o, √© valido dizer que a base est√° praticamente conclu√≠da. O classificador se encontra com uma probabilidade de acerto de 89,5%, apresentando um grande potencial de melhora. Dessa forma, acreditamos que manter o financimento do projeto pode trazer benef√≠cios tanto aos criadores financiados quanto aos financiadores. Para maximizar o sucesso do classificador, algumas breves implementa√ß√µes podem ser introduzidas, como: maior filtragem dos tweets (limpar mais caracteres indesejados) e mais quantidades de tweets. Assim, a manuten√ß√£o do financiamento permitiria que avan√ß√°ssemos no projeto."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
